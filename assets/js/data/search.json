[ { "title": "How to disable the DHCP server on a TP-link Deco mesh network", "url": "/posts/tp-link-deco-dhcp/", "categories": "Networking, DHCP", "tags": "tp-link, deco, wi-fi, network, dhcp, pfsense, firewall", "date": "2023-08-03 00:00:00 +0100", "snippet": "How to disable the DHCP server on a TP-link Deco mesh networkI recently moved house and, for the first time ever, was able to upgraded my broadband to fibre to the premises. This is great, and I no...", "content": "How to disable the DHCP server on a TP-link Deco mesh networkI recently moved house and, for the first time ever, was able to upgraded my broadband to fibre to the premises. This is great, and I now have a superfast internet connection. Only problem being that my old pfSense firewall/router cannot keep up with how fast it now needs to route the traffic. When I did the original pfSense install, I got lucky with a USB 3 NIC that miraculously just worked first time with the intel atom based Dell Wyse nuc I had to hand. But after an unfortunate incident the NIC got damaged leading to me resorting to me moving to a VLAN based setup sharing the only onboard NIC. For the most part it ticked along fine but, now that I have a faster WAN connection, as soon as someone tries to use more bandwidth than the interface resets causing packets to drop. Interestingly nothing appears in the pfSense logs when this happens which has made it almost impossible to troubleshoot. An upgrade to pfSense+ has made it a little bit more reliable, but under high load the interface still is not up to it. The move also coincided with me deciding it was time to purchase a TP-Link Deco mesh Wi-Fi system. The thought process behind this was twofold. First off, I had been paying ¬£10 a month for almost two years for a Wi-Fi extender from my broadband provider. Quick maths estimates that I had spent nearly ¬£300 on a pretty mediocre Wi-Fi extender that I had zero control over. Second. I was facing having to add all of my Wi-Fi based smart home devices to a new network again. This has, of course, organically grown over the past few years a couple of devices at a time and never had to move all at once. The hope was the mesh nature of the Deco system would allow me to up or down scale the network for any further moves, and also never have to rejoin all the devices in one go.The work aroundNow I know that I could upgrade to a more suitable host, or even buy an actual netgate device, but I don‚Äôt really have the time to fully rebuild my network. So I came up with the genius idea. Why does pfSense have to be the default gateway? Could I not just turn off the DHCP server on the Deco side and allow it to do most of the heavy lifting and only have devices that need to talk to the other network talk to pfSense? This method would allow every day devices that are bandwidth hungry; the TV, The Wife‚Äôs phone etc; a direct route out to the fibre connection and then I can use my local DNS server to provide access to anything in another network that might need it. ISP modem ‚Üí TP-Link Deco (in router mode) ‚Üê pfSense as the DHCP server. The only problem? You can‚Äôt turn off the DHCP server on a Deco mesh in router mode ü§¶üèΩ. After surfing through the forums there have been many promises from, I am assuming, TP-Link support that it is an idea that has been passed on to R&amp;D. But now over 2 years since these posts I am facing the same problem. This obviously means that it is not a high priority for TP-Link, again I assume, as people who wish to run their own DHCP server are only a small subset of their customer base.The solutionAfter about half a day of sulking, The Wife was not best pleased with the lack of internet, I wondered what would happen if I created a small DHCP pool in the Deco system but then filled all addresses with fake devices. The question is what would happen if Deco wanted to hand out IPs but didn‚Äôt have any to give? Now, having two unconnected DHCP servers in a network is normally a big no no, but in theory this might work. The first slight gotcha is that the smaller DHCP pool you can create on the Deco is 20 addresses. While I‚Äôd rather not have lost these 20 addresses, I deemed a roughly 7% sacrifice to be an acceptance exchange to using my own DHCP server. Filling the address pool took a good few minutes of me typing out static reservations on my phone. The first few attempts were a bit of a flop. Apparently the MAC addresses 00:00:00:00:00:00 and 00:01:02:03:04:05 are not valid addresses. Go figure. I eventually resorted to a googling a fake MAC address generator, which gave me an address that Deco accepted as real. To keep things simple, I matched the last 2 digits of the MAC address with the last 2 digits of the final octet of the IP address. This isn‚Äôt strictly necessary, but it keeps the static address page looking pleasing, clean. The slightly less pleasing part is I had to stack those 20 address right in the middle of my subnet. As pfSense already had static assignments both at the beginning and the end, I chose to use the range 192.168.x.150-192.168.x.169. In hindsight, I probably could have used 192.168.x.180-192.168.x.199 as nothing had yet been assigned there, but I have now typed everything out now, so it‚Äôs staying put. This also means I had to split my DHCP pool in pfSense to accommodate this mini pool. Once this has all been configured, it‚Äôs time to give it a whirl. Time to find out if I had found a hacky way around the problem, or had I broken the internet even more and annoyed The Wife further by not unpacking more boxes. Miraculously, it actually worked with my laptop picking up an address from pfSense, rather than not being able to connect as it previously has when I filled the entire Deco DHCP pool with fake MAC addresses.How DHCP actually worksBefore we dive into why this works, we should probably do a brief recap of how the DHCP request process actually works, so we know what we are looking for. When a device joins a network, it sends a message called a DHCP discover to port 67 of the IP address 255.255.255.255. This address is known as the broadcast address and the port is, surprise surprise, the one that a DHCP server will listen on. As the name suggests, this message is then broadcast to every device on the network. As the device currently has no IP address, it puts 0.0.0.0 as the source of the packet, but does put its own MAC address in. So if we have one or more DHCP servers listening in the network they will receive this message, on port 67, and respond to it. The server takes that mac address from the packet and has a look at its address table (and because it is all knowing) and if it finds the address then it will respond with the corresponding IP address. If it does not find the IP address, then it will look to see what the next available one is. The server then sends an Offer packet to this new IP address (using our device‚Äôs MAC address) and as switches work on MAC addresses rather than IP address the switches in the network forward this packet to our device. The Offer packet also has a few other bits of configuration bundled along with it. After our device has received the DHCP Offer, it will again broadcast to the entire network (to alert all listening DHCP servers of the intended IP address), again using the address 0.0.0.0 (because it hasn‚Äôt officially been given the OK to use the address yet). The DHCP server will then reply with a DHCP ACK or Acknowledge packet confirming that the device is good to use that IP address. This again happens to that IP address that the server had offered to the device. From this point, that is the IP address that will be tied to that particular MAC address until it expires (There are a few extra configurations passed as part of both the Offer and ACK packages, the expiry is one of these). The final step is any of the other DHCP servers listening in the network will now drop any addresses that had reserved for that MAC address, as they have now been told (by the broadcast DHCP Request packet) that the device is accepting a different address.All of this can be seen in the screenshot below. From the picture you can see that the DHCP server appears to be on the address 10.101.2.1 and the IP address that it is offering us is 10.101.2.226. I‚Äôm not too worried about redacting these IPs, as this packet capture was performed on a public Wi-Fi of a train. So any insight you can gather about the network has very little relevance to me. Normally, it is a bad idea to have more than one DHCP server in the network. The reason for this is if they are not configured correctly then there is the risk of bad IP addresses or duplicates being handed out as the multiple servers do not keep track of address that they haven‚Äôt offered out. I know above I mentioned that you can have multiple DHCP servers, but this is more geared towards having redundant DHCP and is beyond the scope of this post.Proper testingAfter running the setup for a day or so, I started to wonder what was actually going on on the network. To test this, I decided to use Wireshark to test and see what actually happens when a device connects and tries to get an IP address. From the packet capture, you can see that the process is pretty much the same. We have the Deco DHCP server on 192.168.X.254 and pfSense on 192.168.X.253. The only difference is there are a couple of additional packets sent from the Deco DHCP server. These packets are both NAK or Negative acknowledgment. This is the DHCP coming back to tell the device that it does not have any more IP addresses left to assign. If we only had the one DHCP server, then our device would not get and IP address and would not be able to connect to the network. As we do have a second DHCP server, it also receives the broadcasted packets and replies with a DHCP offer which, hopefully, our device accepts. Something else to note is there is an extra DHCP Request and ACK/NAK reply in this packet capture. This is due to me clicking the renew DHCP lease button on macOS, which seems to start the process off by resending the current IP address as a Request.Summing up/TL;DRWhile there is no direct method to disable the DHCP server on a Deco mesh network, it is possible to create a tiny DHCP pool and exhaust it with fake MAC addresses with static assignments. This then forces the Deco DHCP server to negatively reply to any DHCP request made on the network, allowing for our preferred server to assign an IP address. There is a minuscule chance that one day you may buy a device that has a MAC address that matches one of the fakes you have created. If this is the case, then you will probably want to go and replace that static reservation. However, the chances of that happening are extremely low, although slightly increased by the process of randomly generating new MAC addresses for privacy. If this has helped you out, pop a comment below, as others may also find it useful. Likewise, if you 100% disagree with what I‚Äôve written here, have your say below. Or better still rewrite the post and submit a PR against the GitHub repo and I will review and consider your opposing point of view." }, { "title": "How to change some batteries in under 10s", "url": "/posts/battery-change/", "categories": "Theatre sound, Sound No. 2", "tags": "sound, rf, communication, anecdote", "date": "2022-10-25 00:00:00 +0100", "snippet": "How to change some batteries in under 10sI know this might not seem the most impressive thing but how many people could actually change the batteries in a device they have this quickly? It definite...", "content": "How to change some batteries in under 10sI know this might not seem the most impressive thing but how many people could actually change the batteries in a device they have this quickly? It definitely takes my wife longer than this to even get the battery cover off the TV remote.Some backstoryAs I have alluded to many times my full time job is working as a Theatre Sound No. 1 on a show in London. For the majority of my time I am on the desk mixing the mics. But for a couple of shows a week I cover the off-stage sound track. This means I am responsible for prepping the mics before the show, testing they all work, fitting them on the actors, swapping any shared radio packs between actors and monitoring the health of the packs. Normally it‚Äôs a pretty straight forward role. However, the complexity comes from one of the actors only spending about five minutes off-stage for the whole two and a bit hour playing time. And, of course, this actor‚Äôs battery dropped to 20% (1 bar) five minutes after we had started back from the interval.The kitThe hardwareWe have a slightly unique setup with the show being housed in a Grade II listed building with extremely thick walls and a lot of marble. Due to this the travel of the RF doesn‚Äôt travel quite as far as you might hope. So to fix this we have two complete systems (pairs) of Shure ULXD4Q receivers each with their own antennas. And because everything lives on the network we can both monitor date using Wireless Workbench and receive audio for monitoring in WaveTool from Dante. It‚Äôs not an ideal setup, but it‚Äôs making the best of what we have.The batteriesWe use the Ikea LADDA 2450mAh batteries. I know this might be a slightly contriversal choice which is why I am going to explain here why we chose them. Before COVID-19 hit we were using Duracell rechargeable batteries and these were great when the were new, but we had been noticing quite a rapid drop off in the run time we were getting. After about a year of use they were getting hit-and-miss whether they would last the 5-hour call for a show. This lead to us having to swap batteries during the show increasing our reliance on disposable batteries. This is both bad for the environment and the budget. When we reopened, and we found that our almost new 3 sets of Duracell‚Äôs (48 individual batteries) had all seem to have suffered damage (probably because they had been dead for 18 months) I decided that it was time to try something else. After some research some people really liked the fischer amps batteries but at more than the Duracells I wasn‚Äôt keen. Another option would be to get the Shure lithium-ion batteries, but this would have required getting a new charger and changing the rack which we didn‚Äôt have time to do. In the end we went with the Ikea batteries because we could get an extra 16 batteries for the price of 3 sets of the Duracell‚Äôs. The capacity of the batteries was slightly lower, but I figured that with the reduced price we could just get the extra set and change them every show. What I was not expecting was for them to out last our current batteries by a long way. Brand new I would almost risk using them for three shows (about 15 hours run time) and we only dropped to using them for one show after about nine months. I feel like there is quite a bit more I could say on our batteries, so I will stick a link here if I do.A small digressionI did a stint of about four years working aboard Royal Caribbean cruise ships. There we had a lot (read excessive) of the Shure UHF-R series. And, as it never broke, I never felt the need to take photos or write anything down about it. From memory, and after trying to research to find the parts I‚Äôm starting to wonder if I am remembering wrongly, we used four antennas through the theatre (2 in the wings and 2 at the mix position). These four antennas then fed a series of active diversity combiners and distributors that first compared the Stage Left wing and mix antennas and then forwarded the best on as the A antenna for distribution. A similar process then happened on the right side. However, I have not been able to find any reference to a diversity antenna combiner, so this may all be fibs.The prepThe first part of getting the batteries successfully changed was to talk through with all the parties involved. After a quick discussion with the Company Stage Manager (CSM) to weight up the risk of not changing the batteries. While 20% in theory was enough to get the mic to the end of the show, we have always found monitoring in that last bar less accurate. We have seen mics last for over an hour and some die completely in 20 minutes. With another 40 minutes left of the play we decided to go ahead with the swap.The actor has two costume changes during the second part of the show. So the first thing to do was to make sure all the off-stage staff were on the same page. A quick radio to the Deputy Stage Manager (DSM or show caller) to say ‚ÄúHey we‚Äôre going to go for a battery swap, the actor maybe slightly late for their last entrance. We will confirm the cue light once the change has happened.‚ÄùNext I ask the Assistant Stage Manager (ASM) to notify the two cast members that are likely to be impacted most that there maybe a slight delay to the scene resumes. We also let an actor that I am normally swapping a pack to at that point of the show that I will be with her later, but as she has a long time before going on this is less of a problem.The final off-stage person to check in with is the wardrobe dresser who will be doing the quick change with the actor. I explain that we will be doing a battery swap, but she should go ahead and do the quick change first as its more important for the actor to be dressed as the current batteries have a chance of making it to the end if we have to rely on them.The final part: notifying the actor. Now this actor is one I have worked with before. He was in the cast we had before the show closed for Covid and such I knew him quite well. This was a large factor in deciding to change the batteries, if I hadn‚Äôt known him so well it might have been a ‚ÄúHey your batteries are low but should get you to the end of the show.‚Äù Rather than what followed. And this is how it went down. Me: Hey Owen. This isn‚Äôt going to affect you for Whiskey Chamber (the next scene) but your batteries are low. We‚Äôre going to swap them after your quick change out of Limehouse (the next time he comes off-stage). Owen: OK. What do you need from me? Me: I just need to know where your pack is now. Owen: indicates to where his pack is and heads in to Whiskey ChambersThis chat happened after he had done his quick change and was walking from one side of the stage to the other.The swapSo everyone who needs to know is aware that the swap is going to happen. I have taken a brand-new set of Duracell Industrial batteries (I would probably have reused a set if the actor hadn‚Äôt been one of the five top billing actors) that I tested in the spare pack to ensure that they were definitely full. All that is left now is to do the swap.Owen comes sprinting out of the Chamber (stage) and does his quick change as normal. He then raises his arms and allows me access to his pack that is tucked under his shirt. So now its down to me. First thing is to untuck his shirt and remove the mic pack from the Velcro pouch that we use to hold them. Open the battery cover, take out the old batteries, put the new ones in and put the pack back into the pouch. Nice and simple hey?It‚Äôs not actually that hard to do. The hard bit comes from doing the swap under the pressure of a live show. I can hear the scene change music and know that it is starting to run out. There are two actors who would usually be onstage by now getting a little agitated as this is out of the norm. And finally there is the CSM who came up to hover on the off chance that she will have to stop the show if this goes wrong. I put getting the change down quickly and successfully down to a few key points: I know the actor well, and he trusts that I have his and the show‚Äôs best interests in mind with the call I have made. I know the hardware well, I know that both AA batteries sit in the pack - ‚áæ + left to right in the pack. I know that the pack may not turn back on after I have removed the batteries, even though the power lock is on. So I plan to toggle the power switch whether the pack comes back on this means the power will lock on when I hit the correct position. I am the highest and most experienced person in the technical chain, on-site. At the time my Number 2 was fairly new, and while she had quite a lot of experience, she may have second guessed herself when asked to justify it to the CSM.After the show I checked in with the DSM, and she said we added about 10s to the timing breakdown for that scene from the average runtime. This is actually less time than if the scene change goes poorly. The only thing that went wrong during the swap was that the other actor waiting to go in decided to be helpful and confirm the cue light while he was standing around waiting. Luckily, out of the corner of my eye, I saw him do it and was able to radio the DSM to let her know that we weren‚Äôt actually ready yet.The gistWhat this boils down to is to know your kit, the people you are working with and to follow your gut. Yes those batteries may have made it to the end of the show but if they hadn‚Äôt then it would be much worse for Owen as he would have had to push harder at the end of a long show for him." }, { "title": "Home Assistant Alexa smart home integration over Cloudflare", "url": "/posts/home-assistant-alexa-cloudflare/", "categories": "Home Assistant, Cloudflare", "tags": "hass, homeassistant, cloudflare, firewall", "date": "2022-07-01 00:00:00 +0100", "snippet": "Today I decided it was the day that I was going to manage to get Alexa to talk to my Home Assistant (HA). There are a couple of things that made this slightly difficult for me. The first was that I...", "content": "Today I decided it was the day that I was going to manage to get Alexa to talk to my Home Assistant (HA). There are a couple of things that made this slightly difficult for me. The first was that I had limited access to my domain only to the UK. The second was a setting I didn‚Äôt even know was on but after finding it I didn‚Äôt want to turn it off. Something that made it a little hard to track down was that the error message was being masked by an error that is commonly encountered during the setup process.TL;DRIf you are running your Home Assitant instance through Cloudflare and your Alexa cannot connect or successfully get an authentication token then check your Bot Fight setting and Web Application Firewall rules.The Back StoryWhen I first started self-hosting I was getting some random hits on my domains. For some reason, someone in Singapore seemed to think I was running a WordPress site on my domain and kept trying to hit the admin page. So just to be safe I decided to set up a WAF (although it was just called firewall rules back then) rule to only allow traffic in from the United Kingdom. This seemed like a sensible decision as I live in the UK and could always add a new rule if I was going to spend any amount of time in a foreign country.Solving the first problem - Wrong countryFrom the photo above you can see that I was getting an INVALID_AUTHORIZATION_CREDENTIAL error. What I didn‚Äôt realize for a very long time is that the body of my error was different from the one that was in the video tutorial I was following. After realizing that I had a different error I straight away started to google it. What took me the longest was tracking down what was causing the 1020 error. Eventually, I realized that it was coming from Cloudflare and not from my Home Assistant server. Once I knew which logs I should be looking at it was much easier to track down the exact problem to fix it. It turns out that it was because of the decision I had taken a year ago that I explained above. To test my theory I added the county that I was using to run my AWS Lambda function into another rule and, hey presto, I was able to get a response back from my HA server.Solving the second problem - BotsThe next problem was not quite so easy to track down. Once I had the Lambda function working I moved on to trying to get the authentication going. Knowing that it was probably my WAF that was going to be causing the problem gave me a head start on tracking the problem down. Watching the logs as I tried to sign in showed that several requests were being issued a JavaScript bot challenge. And as it was a bot trying to sign in it was of course failing to do so. A slightly secondary issue was that the bot seemed to be coming from the USA and not Ireland or the United Kingdom as I had been expecting.To start with I thought that adding another WAF rule to allow both the USA and Known Bots might be the solution. This didn‚Äôt work as expected.I‚Äôm not sure why but Cloudflare‚Äôs bot fight security setting seems to be the ultimate rule. There is no way to override it. The second problem is there are a lot of people and/or servers in the US that I didn‚Äôt particularly want to access my home automation. This meant I wanted to narrow down the scope of a WAF rule that might let traffic in. I finally settled on a rule that ensured that the country was the USA, the hostname being requested matched that of my public-facing HA subdomain and finally the URI path matched that it needed to get the correct authorization token. The final rule looked something like this:(ip.geoip.country eq \"US\"andhttp.host eq \"&lt;subdomain&gt;.&lt;domain&gt;.&lt;tld&gt;\"andhttp.request.uri.path eq \"/auth/token\") N.B. This should be one continuous line but I have broken it up in an attempt to make it easier to read.This, after all of my previous WAF fun, surprisingly worked.Combining the WAF rulesUnfortunately, I was now using 4 out of my 5 free WAF rules on my Cloudflare account so the next problem became combining the rules all into one. There seems to be a slight bug in the Cloudflare WAF rules that the following very simple block rule:(ip.geoip.country ne \"GB\") or (ip.geoip.country ne \"IE\") N.B. This should be one continuous line but I have broken it up in an attempt to make it easier to read.Just blocks everything as GB is not IE and IE is not GB. Not the most useful. Luckily if you start building more complex rules this flaw doesn‚Äôt seem to hold up. That means we can use something like the following:(ip.geoip.country eq \"IE\"andhttp.host eq \"&lt;subdomain&gt;.&lt;domain&gt;.&lt;tld&gt;\"andhttp.request.uri.path eq \"/api/alexa/smart_home\")or(ip.geoip.country eq \"US\"andhttp.host eq \"&lt;subdomain&gt;.&lt;domain&gt;.&lt;tld&gt;\"andhttp.request.uri.path eq \"/auth/token\")or(ip.geoip.country eq \"GB\") N.B. This should be one continuous line but I have broken it up in an attempt to make it easier to read.Summing upSo now I have one firewall rule that is controlling the access to my domain and whilst I would have liked to keep the Bot Fight setting turned on I think I have reduced the chance of getting unwanted hits. I hope that this may help someone else in the future as it took me a fair chunk of the day to finally work out why the tutorial was failing." }, { "title": "Restarting the blog", "url": "/posts/coming-back/", "categories": "About, blogging", "tags": "restarting, blog", "date": "2022-06-13 00:00:00 +0100", "snippet": "Unfortunately, I have not been blogging over the last 6 months or so. This is because I have returned to my full-time job on the West End and due to many Covid complications I have not had the time...", "content": "Unfortunately, I have not been blogging over the last 6 months or so. This is because I have returned to my full-time job on the West End and due to many Covid complications I have not had the time or the will to be blogging. Now that we have now bedded into our second cast and things are running much more smoothly, I have a bit more time on my hands. I am currently working on a post about my first attempt at CI/CD, but if there is a topic you think I should write about (preferably relating to theatre sound or lighting) then pop in a comment and I will see about writing some content on it.Hopefully, my next post will be out in a week or so, and then a couple of times a month from there onwards." }, { "title": "Controlling Blackmagic Design Smart Videohubs from QLab", "url": "/posts/blackmagic/", "categories": "qlab, blackmagic", "tags": "qlab, blackmagic, python, applescript", "date": "2021-10-15 00:00:00 +0100", "snippet": "Controlling Blackmagic Design Smart Videohubs from QLab is always a little bit difficult. There are network cues built into QLab but the required TCP cue does not exist. However, it is fairly simpl...", "content": "Controlling Blackmagic Design Smart Videohubs from QLab is always a little bit difficult. There are network cues built into QLab but the required TCP cue does not exist. However, it is fairly simple to create a python script to give us this functionality and call that from within anBack in the summer of 2021, I was working on a small show that used eight cameras recording into eight Blackmagic Design HyperDecks. As part of this system, there was a Smart VideoHub. A way to control all of this equipment was missed off the list. So I ended up writing a set of scripts to allow control Blackmagic Design video equipment from QLab. I have planned to clean up the scripts and make them available to the public. But this project is currently sat on the back burner. I have released this script as there is a user on one of the groups who has a similar problem to myself and I feel that this might help them.This script is intended to allow for the control of a single unit over TCP/IP. And was created to allow control from the show control software QLab. However, it can also be run manually, where it should be cross-platform compatible.This script is written in python V2, as this is the default version that ships with macOS. If you have a different version of python running on your mac or PC I believe it will still work, however, I haven‚Äôt had the chance to test it.Input and output numbers are normalized by the script to allow for human numbering to be used.Usage for controlling VideoHub from QLabDownloading the script from GitHub and save it as smarthubctl.pyAll methods of use require the placeholder to be changed for the IP address of the Smart Videohub unit. For example, the lineshould read something like address = \"192.168.1.100\".Using the script from the command line called in the following way: python smarthubctl.py *input* *output*To run the script from QLab. Call the python script from an AppleScript cue like so: 'do shell script \"python /path/to/script/smarthubctl.py *input* *output*\"'This script was intended to be a simple way of controlling Blackmagic Design Smart Videohubs from QLab. Hopefully, you will find it useful." }, { "title": "Armv6 node-exporter on Raspberry Pi 1B+", "url": "/posts/armv6-node/", "categories": "Raspberry Pi, node-exporter", "tags": "raspberrypi, pi1b+, node-exporter", "date": "2021-09-16 00:00:00 +0100", "snippet": "After sending a good few hours trying to get Prometheus node-exporter to work on a Raspberry Pi 1B+ I found that it didn‚Äôt actually support armv6. I spent some time hunting around and found this im...", "content": "After sending a good few hours trying to get Prometheus node-exporter to work on a Raspberry Pi 1B+ I found that it didn‚Äôt actually support armv6. I spent some time hunting around and found this image by ndanyluk. However, documentation on it is very scarce so I thought I‚Äôd jot down how I managed to get it to work in the hope it might help someone else.Using the prom/node-exporter on armv7 onwards (Raspberry Pi 2 upwards)The command I had been using to run node-exporter normally looks something a bit like this:sudo docker run --net=\"host\" --pid=\"host\" -v \"/:/host:ro,rslave\" \\ --name=\"node-exporter\" prom/node-exporter:latest --path.rootfs=/host.Let‚Äôs break it down the node-exporter commandThe usual sudo docker run calls the docker command with superuser privileges and tells it we want to run a new container.--net=\"host\" --pid=\"host\" instructs the new container to use the host‚Äôs already existing network stack. This improves the performance as NAT (Network Address Translation) is not required. However, this does mean we need to manage our ports carefully as this can lead to conflicts. I don‚Äôt have a service already running on the required port (9100) so I don‚Äôt have to worry about this. And the also allows the container to access the process tree on the host. Which in this case allows the container to scrape data from the host.This next argument is a little complicated. -v \"/:/host:ro,rslave\". It starts off well, -v \"/:/host adds the root of the host to the container as a volume mounted in the /host directory. Now we get the bit that we usually leave off. :ro, mounts the drive as a read-only partition (probably a good thing for a monitoring tool). And the final part dictates that the mount can only be used in one direction.The rest of the command is pretty straightforward with the --name argument setting the name of the container. And the final part is the image we want to use. In this case, it‚Äôs the ndanyluk version of node-exporter. The very final argument tells the container that it should create the binary from the host‚Äôs root file system.How is armv6 different to other arm command?So now how do we get node-exporter running on the armv6 platform of a Raspberry Pi 1B+? As there is no documentation for the ndanyluk‚Äôs version of the node exporter it took me a little while to work out how to get it going. I eventually stumbled across the answer in his GitHub repository for the project. One of the files in the repo is a test script that automatically spins up a container from the image that is built to allow for testing. And in this script, there is a subtle difference in the command being called. Here it is below, see if you can spot the difference.sudo docker run --net=\"host\" --pid=\"host\" \\ -v \"/:/host:ro,rslave\" \\ -v \"/etc/hostname:/etc/nodename\" \\ --name=\"node-exporter\" ndanyluk/ \\ node-exporter-armv6:latest --path.rootfs=/hostYou got it. The subtle difference is that we have to mount the hostname file into the container as the nodename file. Now when we run the container it loads up without any errors and provides the data we need to export to a system like Prometheus so we can make some super sexy dashboards of all of those stats we all love.So this is how I got node-exporter running on the armv6 platform. I hope that someone finds this useful and that it saves them a little time.Prometheus logo by Alexander Schwartz (ahus1)[1][2] ‚Äì https://github.com/prometheus/docs/raw/ca2961b495c3e2a1e4586899c26de692fa5a28e7/static/prometheus_logo_orange_circle.svg,Apache License 2.0, https://commons.wikimedia.org/w/index.php?curid=85744651" }, { "title": "Getting more analytics for a free Cloudflare account", "url": "/posts/free-cloudflare-analytics/", "categories": "Cloudflare, Analytics", "tags": "cloudflare, analytics, free", "date": "2021-08-13 00:00:00 +0100", "snippet": "Ever wished that you could get more Cloudflare analytics for free? But don‚Äôt want to upgrade your Cloudflare account? So here‚Äôs a hacky way to get a little more data out of the free features that y...", "content": "Ever wished that you could get more Cloudflare analytics for free? But don‚Äôt want to upgrade your Cloudflare account? So here‚Äôs a hacky way to get a little more data out of the free features that you can access.The preambleAs you can see here I have my Cloudflare domain overview dashboard. Now I understand why there are limits to what the free account can access. Storing and crunching through a lot of data can be expensive. And yes there is an analytics page but for my site, it‚Äôs extremely sparse in both data and views.Now. There is an obvious solution. We could pay for the Pro plan (which at $20 might just be a bargain). Or we could upgrade a WordPress plugin (once again this involves money). But as you can see from my overview, I don‚Äôt get a lot of traffic. This now makes me think it might not be worth it.The gathering of facts from CloudflareOn a side note, I noticed that my ‚ÄúrouteMeHome‚Äù domain had had a few firewall events pop up. So being slightly bored and curious as to why these event logs were I opened one up. And this is what I found:The interesting parts of this log to me were mainly the Host and Path fields. The firewall allows me to view much more details on the request that had been blocked than the analytics page allows. So an idea pops into my head. The firewall has both a deny and an allow mode. So what happens if I allow everyone access? And the second. How do I allow everyone?The first idea was could I just allow IP addresses ..., however, Cloudflare were ahead of me here, and could tell it was not a valid IP address. Next though. What happens if I allow 255.255.255.255, the network broadcast address, or 0.0.0.0, the magic placeholder that sometimes works. But no neither of these worked either.The Eureka momentI went back to the original firewall event log and checked why it was there. It turns out that earlier that day I decided that as I have no plans to leave the country any time soon, damn you Covid-19, I had blocked all requests that originate from outside the UK. From this, I decided to create a firewall rule to allow all countries other than one. And then include that one back in again as a second part to the rule. The only problem is which country do I pick? I finally settled on Antarctica a) because I‚Äôm lazy and this meant I didn‚Äôt have to scroll too far. And b) I doubt there are many people in Antarctica trying to read my blog so if this rule breaks the access then it‚Äôs probably not the end of the world.(If you are in Antarctica and are having problems accessing my blog let me know and I‚Äôll pick a different country).The testing our analyticsNow that I have a rule in place that seems to be doing what I want, let us see what sort of data it is giving me.And low and behold I have access to that valuable Host and Path information for every request that hits my domain. This is now starting to look like the Cloudflare analytics for free that I promised back at the top of the page. (And yes this one was added because the Yoast algorithm told me I need to use my key phrase one more time).The summing upNow, I‚Äôm not saying this is a good idea. Or that even it replaces the Cloudflare analytics section. And in the few hours that I have had this running, I have generated around 18750 firewall event logs. Most of these are from me just editing this post with the way WordPress has been calling page content. At this moment I almost have the complete opposite problem with now having far too much data to process. This is just a way I found to get some extra Cloudflare analytics for free. But I think what and how I can use this data may fall under a different post. For now, I can pull the firewall logs and comb through them trying to work out what on my blog works and what doesn‚Äôt.The Cloudflare firewall orderIt appears that the firewall operates in a single match top-down fashion. This means that as soon as it finds a rule that matches it stops checking for any others. This means that the allow all rule needs to be at the bottom. By doing this any other rules you have to block access will match first and then as a last resort the firewall will log the request.The disclaimerI am unsure whether this is a good or a bad idea. Or even if it is something we should be allowed to do. However, it does currently work but if for some reason Cloudflare does change their system to block this I will add an update to the top of this post declaring it broken." } ]
